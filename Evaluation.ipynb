{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from math import log10, sqrt\n",
    "import cpbd\n",
    "\n",
    "def calculate_psnr(image1, image2):\n",
    "    r\"\"\"Compute Peak Signal-to-Noise Ratio\n",
    "    Args:\n",
    "        image1          :   numpy.ndarray([H, W, C], dtype=np.float32)\n",
    "        image2          :   numpy.ndarray([H, W, C], dtype=np.float32)\n",
    "    Returns:\n",
    "        PSNR            :   float (â†‘)\n",
    "    \"\"\"\n",
    "    mse = np.mean((image1 - image2) ** 2)\n",
    "    if(mse == 0):  # MSE is zero means no noise is present in the signal .\n",
    "                  # Therefore PSNR have no importance.\n",
    "        return 100\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "total_ssim = []\n",
    "total_psnr = []\n",
    "total_cpbd = []\n",
    "for i in range(6):\n",
    "    ssim_emo = 0\n",
    "    psnr_emo = 0\n",
    "    cpbd_emo = 0\n",
    "    img_list = sorted(glob(os.path.join(f'/root/TalkingHeadProject/imaginaire/logs/result_CREMAD/00{i+1}', '*')))\n",
    "\n",
    "    for pred_file in tqdm(img_list):\n",
    "        gt_file = pred_file.replace(f'/root/TalkingHeadProject/imaginaire/logs/result_CREMAD/00{i+1}',\n",
    "                                    f'/root/TalkingHeadProject/imaginaire/logs/result_CREMAD/00{i+1}_real')\n",
    "        pred_image = cv2.imread(pred_file, cv2.IMREAD_GRAYSCALE)\n",
    "        gt_image = cv2.imread(gt_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # SSIM\n",
    "        ssim_score = ssim(pred_image, gt_image)\n",
    "        ssim_emo = ssim_emo + ssim_score\n",
    "        \n",
    "        #PSRN\n",
    "        psnr_score = calculate_psnr(pred_image, gt_image)\n",
    "        psnr_emo = psnr_emo + psnr_score\n",
    "        \n",
    "        #CPBD\n",
    "        cpbd_score = cpbd.compute(pred_image)\n",
    "        cpbd_emo = cpbd_emo + cpbd_score\n",
    "        \n",
    "    # print(f\"SSIM {i+1}: {ssim_emo/len(img_list)}\")\n",
    "    total_ssim.append(ssim_emo/len(img_list))\n",
    "    total_psnr.append(psnr_emo/len(img_list))\n",
    "    total_cpbd.append(cpbd_emo/len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result:\")\n",
    "print(total_ssim)\n",
    "print(f\"Avg SSIM: {sum(total_ssim)/len(total_ssim)}\")\n",
    "print(total_psnr)\n",
    "print(f\"Avg PSNR: {sum(total_psnr)/len(total_psnr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_cpbd)\n",
    "print(f\"Avg CPBD: {sum(total_cpbd)/len(total_cpbd)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lpips\n",
    "import torch\n",
    "loss_fn_alex = lpips.LPIPS(net='alex') # best forward scores\n",
    "loss_fn_vgg = lpips.LPIPS(net='vgg') # closer to \"traditional\" perceptual loss, when used for optimization\n",
    "\n",
    "total_lp = []\n",
    "for i in range(6):\n",
    "    lp_emo = 0\n",
    "    img_list = sorted(glob(os.path.join(f'/root/TalkingHeadProject/imaginaire/logs/result_CREMAD/00{i+1}', '*')))\n",
    "\n",
    "    for pred_file in tqdm(img_list):\n",
    "        gt_file = pred_file.replace(f'/root/TalkingHeadProject/imaginaire/logs/result_CREMAD/00{i+1}',\n",
    "                                    f'/root/TalkingHeadProject/imaginaire/logs/result_CREMAD/00{i+1}_real')\n",
    "        pred_image = cv2.imread(pred_file)\n",
    "        gt_image = cv2.imread(gt_file)\n",
    "        \n",
    "        pred_image = torch.from_numpy(np.transpose(pred_image, (2, 0, 1))).float() / 255.0\n",
    "        gt_image = torch.from_numpy(np.transpose(gt_image, (2, 0, 1))).float() / 255.0\n",
    "\n",
    "        lp_score = loss_fn_vgg(pred_image, gt_image)\n",
    "        lp_emo = lp_emo + lp_score\n",
    "    print(f\"LPIPS {i+1}: {lp_emo/len(img_list)}\")\n",
    "    total_lp.append(lp_emo/len(img_list))\n",
    "print(f\"Avg LPIPS: {sum(total_lp)/len(total_lp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lp"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
